According to your suggestion I updated the merge-json.mjs file and Run Playwright test but getting below error:
Now is showing error my each job

* Run Playwright Tests
Run # Ensure pipefail is set so the exit status of the first command in a pipeline is used.
Error: Cannot find module 'json:./raw-results/results.json'
Require stack:
- /home/runner/work/hammertime-auto-playwright-tests/hammertime-auto-playwright-tests/Playwright-Automation/node_modules/playwright/lib/program.js
- /home/runner/work/hammertime-auto-playwright-tests/hammertime-auto-playwright-tests/Playwright-Automation/node_modules/@playwright/test/cli.js
    at Module._resolveFilename (node:internal/modules/cjs/loader:1212:15)
    at Function.resolve (node:internal/modules/helpers:193:19)
    at resolveReporter (/home/runner/work/hammertime-auto-playwright-tests/hammertime-auto-playwright-tests/Playwright-Automation/node_modules/playwright/lib/program.js:333:18)
    at /home/runner/work/hammertime-auto-playwright-tests/hammertime-auto-playwright-tests/Playwright-Automation/node_modules/playwright/lib/program.js:327:40
    at Array.map (<anonymous>)
    at resolveReporterOption (/home/runner/work/hammertime-auto-playwright-tests/hammertime-auto-playwright-tests/Playwright-Automation/node_modules/playwright/lib/program.js:327:30)
    at overridesFromOptions (/home/runner/work/hammertime-auto-playwright-tests/hammertime-auto-playwright-tests/Playwright-Automation/node_modules/playwright/lib/program.js:287:15)
    at runTests (/home/runner/work/hammertime-auto-playwright-tests/hammertime-auto-playwright-tests/Playwright-Automation/node_modules/playwright/lib/program.js:167:24)
    at async t.<anonymous> (/home/runner/work/hammertime-auto-playwright-tests/hammertime-auto-playwright-tests/Playwright-Automation/node_modules/playwright/lib/program.js:55:7) {
  code: 'MODULE_NOT_FOUND',
  requireStack: [
    '/home/runner/work/hammertime-auto-playwright-tests/hammertime-auto-playwright-tests/Playwright-Automation/node_modules/playwright/lib/program.js',
    '/home/runner/work/hammertime-auto-playwright-tests/hammertime-auto-playwright-tests/Playwright-Automation/node_modules/@playwright/test/cli.js'
  ]
}
Test exit code: 1
Error: Process completed with exit code 1.

* what should I do?

* here is my complete yaml:

name: Multiple Jobs Test
on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]
  # schedule:
  #   - cron: '30 13 * * 5'  

permissions:
      contents: read
      id-token: write
      pull-requests: write
      issues: write    
jobs:
  test:
    timeout-minutes: 100
    runs-on: ubuntu-latest-16-core-internal
    strategy:
      matrix:
        group: [
          # { file: 'Playwright-Automation/tests/cf_AutoTest/bscdownpayment/01_BSC-Silver-Lockdown-SC-NB.spec.ts', name: 'BSC Silver New Business Group 1' },
          # { file: 'Playwright-Automation/tests/cf_AutoTest/bscdownpayment/02_BSC-Bronze-Lockdown-SC-NB.spec.ts', name: 'BSC Bronze New Business Group 2' },
          # { file: 'Playwright-Automation/tests/cf_AutoTest/bscdownpayment/03_BSC-Gold-Lockdown-SC-NB.spec.ts', name: 'BSC Gold New Business Group 3' },
          # { file: 'Playwright-Automation/tests/cf_AutoTest/foreignDriversLicense/CFA_Auto_FDL-CF1-NB.spec.ts', name: 'FDL CF1 New Business Group 4' },
          # { file: 'Playwright-Automation/tests/cf_AutoTest/foreignDriversLicense/CFA_Auto_FDL-CF2-NB.spec.ts', name: 'FDL CF2 New Business Group 5' },
          { file: 'Playwright-Automation/tests/cf_AutoTest/restrictedOperator/Restrict_Operator_Tests.spec.ts', name: 'Restrict Operator Tests Group 6' },
          # { file: 'Playwright-Automation/tests/cf_AutoTest/tiktok_theft/CFA_Auto-TikTok-theft.spec.ts', name: 'TikTok Theft Tests Group 7' },
          # { file: 'Playwright-Automation/tests/cf_AutoTest/unbindableVehicles/Cost_New_Unbind Vehs.spec.ts', name: 'Cost New Unbindable Vehicles Tests Group 8' },
          # { file: 'Playwright-Automation/tests/cf_PropertyTest/Aerial Runway Pause/CFP_Property_Aerial_Runway_Pause.spec.ts', name: 'Aerial Runway Pause Tests Group 9' },
          { file: 'Playwright-Automation/tests/cf_PropertyTest/inspectionScoreCard/inspectionScoreCard.spec.ts', name: 'Inspection ScoreCard Tests Group 10' },
          # { file: 'Playwright-Automation/tests/cf_PropertyTest/NH_Pause/CFP Property_NH-Pause.ts', name: 'NH_PC9-PC10_Pause Tests Group 11' },
          ]

    name: ${{ matrix.group.name }}  # Custom job name
    env:
      CI: true
    steps:
    - uses: actions/checkout@v4
    - uses: lmigtech/internal-actions/actions/setup-node@v0
      with:
          node-version: "20"
          cache: "npm"
          cache-dependency-path: "**/package-lock.json"
          working-directory: ./Playwright-Automation

    - name: Install Playwright Browsers
      run: npx playwright install --with-deps
      working-directory: ./Playwright-Automation

    - name: Install Additional Dependencies(ffmpeg and xvfb)
      run: |
       sudo apt-get update
       sudo apt-get install -y ffmpeg xvfb
      shell: bash

      #install ffmpeg for screen recording
    - name: Install ffmpeg for screen recoding
      run: sudo apt-get install ffmpeg -y

      #start virtual display (xvfb) for headless browser
    - name: Start Xvfb(Virtual Display)
      run: |
        Xvfb :99 -screen 0 1920x1080x24 -ac -nolisten tcp &
        sleep 3 #Allow time for Xvfb to fully start
      shell: bash

      #Start recording the entire test execution
    - name: Start screen recording with ffmpeg
      run: |
        ffmpeg -y -f x11grab -video_size 1920x1080 -i :99 -r 30 -c:v libx264 -preset ultrafast -pix_fmt yuv420p test_execution.mp4 &
        sleep 2
      shell: bash

       #run playwright tests
    - name: Run Playwright Tests
      id: run_tests
      run: |
        # Ensure pipefail is set so the exit status of the first command in a pipeline is used.
        set -o pipefail
        EXIT_CODE=0
        # Run the tests. If npx playwright test exist nonzero, capture its exit code.
        DISPLAY=:99 npx playwright test ${{ matrix.group.file }} --project="Google Chrome" --workers=1 --headed --reporter=json:./raw-results/results.json 2>&1 | tee test_output.txt || EXIT_CODE=$?
        echo "Test exit code: $EXIT_CODE"
        # Set the exit code as a workflow output
        echo "exit-code=$EXIT_CODE" >> $GITHUB_OUTPUT
        # Exit with the captured code (this step is marked continue-on-error so subsequent steps run)
        exit $EXIT_CODE
        # Check for flaky tests in the report
           if grep -q '"status": "flaky"' report.json; then
             echo "Flaky tests detected in ${{ matrix.group.file }}."
             exit 1
           fi
           # Exit with the original exit code if no flaky tests were found
           exit $exit_code
      working-directory: ./Playwright-Automation
      continue-on-error: true
 

      #stop screen recording after tests complete
    - name: Stop screen recording
      if: always()
      run: |
       if pgrep ffmpeg; then
        echo "Stop screen recording..."
        pkill ffmpeg
        sleep 3 # Allow ffmpeg to finalize the file
       else
        echo "WARNING: ffmpeg was not running!"
        cat ffmpeg_log.txt
       fi
      shell: bash

      #Ensure video file was created
    - name: Ensure Video Exists
      if: always()
      run: |
       if [ ! -f test_execution.mp4 ]; then
        echo "ERROR: test_execution.mp4 was not created!"
        exit 1
       fi
      shell: bash

      #Upload individual test videos (Deletes after 1 days)
    - name: Upload individual test execution video
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: Test-Videos-${{ matrix.group.name }} 
        path: ./Playwright-Automation/test-results/**/*.webm
        retention-days: 1 
      
      #Upload the full test execution screen recording (deletes after 1 days) 
    - name: Upload full test execution video
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: Full-Video-${{ matrix.group.name }} 
        path: test_execution.mp4
        retention-days: 1 

      #Optionally, upload screenshots if any tests failed
    - name: Upload Screenshots
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: Screenshots-${{ matrix.group.name }}  
        path: ./Playwright-Automation/test-results/**/*.png
        retention-days: 1

        # Upload raw JSON result to be used in final merge
    - name: Upload raw test result JSON
      if: always()
      uses: actions/upload-artifact@v4
      with:
       name: Raw-Results-${{ matrix.group.name }}
       path: ./Playwright-Automation/raw-results
       retention-days: 3

      #upload Monocart report (keeps for 15 days)
    - name: Upload Monocart report
      if: always() # changed from if: ${{ !cancelled() }}
      uses: actions/upload-artifact@v4
      with:
        name: Monocart-${{ matrix.group.name }}  
        path: ./Playwright-Automation/monocart-report
        retention-days: 15

      
      # Final check: fail the job if any tests failed
    - name: "Final Check: Fail Job if Tests Failed"
      if: always()
      run: |
        echo "Captured exit code: ${{ steps.run_tests.outputs.exit-code }}"
        if [ "${{ steps.run_tests.outputs.exit-code }}" -ne 0 ]; then
          echo "Some tests failed. Failing job."
          exit 1
        else
         echo "All tests passed."
        fi
      shell: bash

      # added: aggregate job
  aggregate:
    
    name: Aggregate All Artifacts
    runs-on: ubuntu-latest-16-core-internal
    needs: test
    if: always()
    steps:
    - name: Download all artifacts
      uses: actions/download-artifact@v4
      with:
        path: ./all-artifacts  

    - name: List all downloaded files
      run: |
          echo "Downloaded files:"
          find ./all-artifacts   

    - name: Zip all results
      run: |
        zip -r Final-Report.zip ./all-artifacts 
    
    - name: Upload Final Report
      uses: actions/upload-artifact@v4
      with:
        name: Final-Combined-Report
        path: Final-Report.zip
        retention-days: 15  
    


  merge-reports: 
    needs: test  # Changed: use artifact from aggregate job
    runs-on: ubuntu-latest-16-core-internal
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
  
      - name: Download all raw test results
        uses: actions/download-artifact@v4
        with:
          path: raw-collection
  
      - name: 'Debug: List downloaded raw JSON files'
        run: |
          echo "Showing structure of raw-collection/"
          find raw-collection -type f

          # INSERT THIS DEBUG STEP RIGHT HERE
      - name: 'Debug: Show all raw JSON files'
        run: |
          echo "Showing raw JSON files:"
          find raw-collection -type f -name "*.json"
  
      - name: Set npm registry to Cloudflare mirror (avoid E503)
        run: npm config set registry https://registry.npmmirror.com/
  
      - name: Install dependencies
        run: npm ci
        working-directory: ./Playwright-Automation
  
      
      # Run Node script to merge raw test results
      - name: Merge raw JSON results using monocart-reporter API
        run: node merge-json.mjs
        working-directory: ./Playwright-Automation
  
      # Generate HTML from merged result
      - name: Generate final Monocart report
        run: |
          npx monocart-reporter generate merged-results.json --output merged-report
        working-directory: ./Playwright-Automation
  
      - name: Upload merged Monocart report
        uses: actions/upload-artifact@v4
        with:
          name: merged-report
          path: Playwright-Automation/merged-report
